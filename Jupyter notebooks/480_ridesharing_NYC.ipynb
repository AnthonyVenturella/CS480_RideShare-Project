{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import networkx as nx\n",
    "import haversine as hs\n",
    "from haversine import Unit\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Query the database to return all the trips in a 5 minute pickup window****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 300.0\n",
    "\n",
    "conn=pymysql.connect(host='127.0.0.1',port=int(3306),user='root',passwd=' ',db=' ')\n",
    "\n",
    "df=pd.read_sql_query(\n",
    "    \"\"\"SELECT Lpep_pickup_datetime, lpep_dropoff_datetime ,Pickup_longitude, Pickup_latitude, Dropoff_longitude, Dropoff_latitude, Trip_distance, Passenger_count FROM green_data \n",
    "    WHERE Lpep_pickup_datetime >= '2015-01-01  01:00:00' AND Lpep_pickup_datetime <= '2015-01-01 01:05:00'\n",
    "    UNION\n",
    "    SELECT tpep_pickup_datetime, tpep_dropoff_datetime, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, trip_distance, passenger_count FROM yellow_data\n",
    "    WHERE tpep_pickup_datetime >= '2015-01-01  01:00:00' AND tpep_pickup_datetime <= '2015-01-01 01:05:00'\n",
    "    ORDER BY Lpep_pickup_datetime;\"\"\",\n",
    "conn)\n",
    "\n",
    "df = df[(df != 0).all(1)]\n",
    "df['points'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Calculate miles between pickup and dropoff point using haversine distance formula****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_lon = df['Pickup_longitude'].tolist()\n",
    "pickup_lat = df['Pickup_latitude'].tolist()\n",
    "dropoff_lon = df['Dropoff_longitude'].tolist()\n",
    "dropoff_lat = df['Dropoff_latitude'].tolist()\n",
    "before_distance = []\n",
    "\n",
    "for i in range(0, len(dropoff_lat)):\n",
    "    before_distance.append(hs.haversine((pickup_lat[i], pickup_lon[i]), (dropoff_lat[i], dropoff_lon[i]), unit = Unit.MILES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Store this new updated distance into the dataframe for future reference, and also remove rides starting and ending at the same location****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance'] = before_distance\n",
    "df = df[df['distance'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3302 entries, 0 to 3387\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   Lpep_pickup_datetime   3302 non-null   datetime64[ns]\n",
      " 1   lpep_dropoff_datetime  3302 non-null   datetime64[ns]\n",
      " 2   Pickup_longitude       3302 non-null   float64       \n",
      " 3   Pickup_latitude        3302 non-null   float64       \n",
      " 4   Dropoff_longitude      3302 non-null   float64       \n",
      " 5   Dropoff_latitude       3302 non-null   float64       \n",
      " 6   Trip_distance          3302 non-null   float64       \n",
      " 7   Passenger_count        3302 non-null   int64         \n",
      " 8   points                 3302 non-null   int64         \n",
      " 9   distance               3302 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(6), int64(2)\n",
      "memory usage: 283.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Create lists of necessary dataframe columns for easier lookups and reference****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_longitude = df['Pickup_longitude'].tolist()\n",
    "pickup_latitude = df['Pickup_latitude'].tolist()\n",
    "dropoff_longitude = df['Dropoff_longitude'].tolist()\n",
    "dropoff_latitude = df['Dropoff_latitude'].tolist()\n",
    "pickup_time= df['Lpep_pickup_datetime'].tolist()\n",
    "dropoff_time = df['lpep_dropoff_datetime'].tolist()\n",
    "passengers = df['Passenger_count'].tolist()\n",
    "total_distance = df['distance'].tolist()\n",
    "total_time = []\n",
    "\n",
    "for i in range(0, len(dropoff_time)):\n",
    "    total_time.append(int((dropoff_time[i] - pickup_time[i]).total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Increased efficiency of algorithm by converting previous Pandas datetime object to Python datetime object****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_time = [x.to_pydatetime() for x in pickup_time]\n",
    "dropoff_time = [x.to_pydatetime() for x in dropoff_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Sequence calculator to determine if 2 rides are more efficient on their own, or more efficient when merged with a selected minute delay****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence(p1, p2, d1, d2, a,b,c,d,taxi):\n",
    "    trip1 = hs.haversine(p1, p2, unit = Unit.MILES)\n",
    "    trip2 = hs.haversine(p2, d1, unit = Unit.MILES)\n",
    "    trip3 = hs.haversine(d1, d2, unit = Unit.MILES)\n",
    "    \n",
    "    \n",
    "    time1 = pickup_time[b] + datetime.timedelta(minutes=trip1/taxi)\n",
    "    time2 = dropoff_time[c] + datetime.timedelta(minutes=trip2/taxi)\n",
    "    time3 = dropoff_time[d] + datetime.timedelta(minutes=trip3/taxi) \n",
    "    \n",
    "    res = trip1 + trip2 + trip3\n",
    "    \n",
    "    if abs(time1 - pickup_time[b]).total_seconds() >= delay:\n",
    "        return (res, False)\n",
    "    elif abs(time2 - dropoff_time[c]).total_seconds() >= delay:\n",
    "        return (res, False)\n",
    "    elif abs(time3 - dropoff_time[d]).total_seconds() >= delay:\n",
    "        return (res, False)\n",
    "    \n",
    "    return (trip1+trip2+trip3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Implemented possible merging algorithm that was given to us in the Appendix of the project description. If two rides are possible to be merged, store the index of one trip in a map as the key and the other trip index along with the total driven miles in a list associated with that key****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trips = {}\n",
    "G = nx.Graph()\n",
    "for i in range(0, len(pickup_longitude)):\n",
    "    \n",
    "    if passengers[i] >= 3:\n",
    "        continue\n",
    "        \n",
    "    t1_pickup = (pickup_longitude[i], pickup_latitude[i])\n",
    "    t1_dropoff = (dropoff_longitude[i], dropoff_latitude[i])\n",
    "    \n",
    "    d1 = hs.haversine(t1_pickup, t1_dropoff, unit = Unit.MILES)\n",
    "    \n",
    "    if d1 == 0.0:\n",
    "        continue\n",
    "        \n",
    "    s1 = d1/(total_time[i]/60)\n",
    "    \n",
    "    for j in range(i, len(pickup_longitude)):\n",
    "        \n",
    "        if passengers[i] + passengers[j] > 3:\n",
    "            continue\n",
    "            \n",
    "        if i == j:\n",
    "            continue\n",
    "            \n",
    "        t2_pickup = (pickup_longitude[j], pickup_latitude[j])\n",
    "        t2_dropoff = (dropoff_longitude[j], dropoff_latitude[j])\n",
    "        d2 = hs.haversine(t2_pickup, t2_dropoff, unit = Unit.MILES)\n",
    "\n",
    "        if d2 == 0.0:\n",
    "            continue\n",
    "\n",
    "        s2 = d2/(total_time[j]/60)\n",
    "\n",
    "        taxi = (s1+s2)/ 2.0\n",
    "        \n",
    "        seq1 = sequence(t1_pickup, t2_pickup, t1_dropoff, t2_dropoff,i,j,i,j,taxi)\n",
    "        seq2 = sequence(t1_pickup, t2_pickup, t2_dropoff, t1_dropoff,i,j,j,i,taxi)\n",
    "        seq3 = sequence(t2_pickup, t1_pickup, t1_dropoff, t2_dropoff,j,i,i,j,taxi)\n",
    "        seq4 = sequence(t2_pickup, t1_pickup, t2_dropoff, t1_dropoff,j,i,j,i,taxi)\n",
    "\n",
    "        curr_distance = d1 + d2\n",
    "        curr_min = 1000000\n",
    "        merged_trip = ()\n",
    "        flag = 0\n",
    "        \n",
    "        if seq1[0] < curr_distance and seq1[1]:\n",
    "            if seq1[0] < curr_min:\n",
    "                curr_min = seq1[0]\n",
    "                \n",
    "        if seq2[0] < curr_distance and seq2[1]: \n",
    "            if seq2[0] < curr_min:\n",
    "                curr_min = seq2[0]\n",
    "                \n",
    "        if seq3[0] < curr_distance and seq3[1]:\n",
    "            if seq3[0] < curr_min:\n",
    "                curr_min = seq3[0]\n",
    "                \n",
    "        if seq4[0] < curr_distance and seq4[1]:\n",
    "            if seq4[0] < curr_min:\n",
    "                curr_min = seq4[0]\n",
    "                \n",
    "        if curr_min != 1000000:\n",
    "            if i in trips:\n",
    "                trips[i].append((j,curr_min))\n",
    "            else:\n",
    "                trips[i] =[(j,curr_min)]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Create a graph based off of the possible merged trips. The nodes are the indices of the trips and edges are connected only if they have a possibility to be merged. Edge weights are the miles it would take to complete the merged trip.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trips:\n",
    "    for j in trips[i]:\n",
    "        G.add_edge(i, j[0], weight=j[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Run the maximum weight matching algorithm. I used the off the shelf built in max_weight_matching function given in the NetworkX library. https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.matching.max_weight_matching.html****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merged = nx.max_weight_matching(G, maxcardinality=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Math to determine the total amount of miles before the algorithm run, how many miles are going to be driven after the maximum matching algorithm, and the difference. <br>1) Create a set with all trip indices.<br>2) Loop through the result from the maximim matching algorithm summing up miles, and remove indices from set.<br>3) Only indices left in set are now trips that were not merged with another, loop through and add these trips distance to the total.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Merging Distance: 6778.03 miles\n",
      "Original Distance: 7250.89 miles\n",
      "Total Miles Saved: 472.86 miles\n",
      "Percentage of Miles Saved: 6.52%\n"
     ]
    }
   ],
   "source": [
    "merged_distance = 0.0\n",
    "already_matched = set()\n",
    "\n",
    "# Create a set of ALL trip indices\n",
    "for i in range(0, len(total_distance)):\n",
    "    already_matched.add(i)\n",
    "\n",
    "# Remove the two merged trips indices from the set of all indices\n",
    "# Find distance between these two merged indices from previous map\n",
    "# Add that distance found between them to running total\n",
    "for i in merged:\n",
    "    already_matched.remove(i[0])\n",
    "    already_matched.remove(i[1])\n",
    "    if i[0] < i[1]:\n",
    "        trip = trips[i[0]]\n",
    "        search = i[1]\n",
    "    else:\n",
    "        trip = trips[i[1]]\n",
    "        search = i[0]\n",
    "    for j in trip:\n",
    "        if j[0] == search:\n",
    "            merged_distance += j[1]\n",
    "\n",
    "# At this point, the only trips left in the set are trips that were NOT merged\n",
    "# Simply add the distance from the lonesome trip to the running total\n",
    "for i in already_matched:\n",
    "    merged_distance += total_distance[i]\n",
    "\n",
    "print('After Merging Distance: {:.2f} miles'.format(merged_distance))\n",
    "print('Original Distance: {:.2f} miles'.format(sum(total_distance)))\n",
    "print('Total Miles Saved: {:.2f} miles'.format(sum(total_distance)-merged_distance))\n",
    "print('Percentage of Miles Saved: {:.2f}%'.format(100*(1.0-merged_distance/sum(total_distance))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
